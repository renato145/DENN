{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from denn import *\n",
    "import matplotlib as mpl, warnings\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'dis'\n",
    "exps  = ['exp1','exp2','exp3','exp4']\n",
    "funcs = ['sphere','rastrigin','rosenbrock']\n",
    "freq = 20\n",
    "nn_p = 5\n",
    "nn_w = 10\n",
    "nn_tw = 1\n",
    "dimension=30\n",
    "norm_check = np.sqrt(dimension*(10**2)) #10=5-(-5) this line is to normalize error values, we divide them to the biggest distance between two points in decision space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a05a6d9ec3bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../../data/cluster_results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-a05a6d9ec3bf>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(m, normalize)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mnn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nntw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_tw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mnn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nnp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mnonn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_data\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnonn_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#     if normalize:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/denn/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/denn/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No objects to concatenate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "nn_pat = re.compile('.*/(exp\\d)/(\\w*)/nn/freq([0-9\\.]+)nn_w(\\d+)nn_p(\\d+)\\w+nn_tw(\\d+)\\w+div([A-Za-z]+)/(\\w+)_(\\w+)_\\w+.csv')\n",
    "nn_decode_keys = ['experiment','function','freq','nnw','nnp','nntw','div','method','replace_mech']#,\n",
    "\n",
    "pat = re.compile('.*/(exp\\d)/(\\w*)/nonn/freq([0-9\\.]+)div(\\w+)/(\\w+)_\\w+.csv')\n",
    "decode_keys = ['experiment','function','freq','div','method']\n",
    "\n",
    "\n",
    "def get_files(m): return list(path.glob(f'**/nonn/**/*{m}.csv'))\n",
    "def get_nn_files(m): return list(path.glob(f'**/nn/**/*{m}.csv'))\n",
    "\n",
    "def read_csv(f,m):\n",
    "    df = pd.read_csv(f)\n",
    "    for k,v in zip(decode_keys,pat.search(str(f)).groups()): df[k] = v\n",
    "    df['freq'] = df['freq'].astype(float)\n",
    "    df['method'] = df['method'] + '_' + df['div']\n",
    "    df.drop('div', axis=1, inplace=True)\n",
    "    df.rename({'0':m.upper(), m:m.upper()}, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def read_nn_csv(f,m):\n",
    "    df = pd.read_csv(f)\n",
    "    df = df.mean().to_frame().T\n",
    "    for k,v in zip(nn_decode_keys,nn_pat.search(str(f)).groups()): df[k] = v\n",
    "    df['freq'] = df['freq'].astype(float)\n",
    "    \n",
    "    df['method'] =df['method'] + '_' + df['div'] \n",
    "    df['method'] = df['method'].str.replace('NNnorm_Worst', 'NN')\n",
    "    df['method'] = df['method'].str.replace('NNconv_Worst', 'NNconv')\n",
    "    df.drop(['replace_mech','div'], axis=1, inplace=True)\n",
    "#     df = df_mean(df, m)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_data(m, normalize=False):\n",
    "    nn_files = get_nn_files(m)\n",
    "    files = get_files(m)\n",
    "    nn_data = pd.concat([read_nn_csv(f,m) for f in nn_files])\n",
    "#     data = data[data.nnp.isna() | (data.nnp == str(nn_p))].drop('nnp', axis=1)\n",
    "#     i added this to only consider nn_w = 5\n",
    "    nn_data = nn_data[nn_data['nnw']==str(nn_w)]\n",
    "    nn_data = nn_data[nn_data['nntw']==str(nn_tw)]\n",
    "    nn_data = nn_data[nn_data['nnp']==str(nn_p)]\n",
    "    nonn_data = pd.concat([read_csv(f,m) for f in files])\n",
    "    data = pd.concat([nn_data , nonn_data])\n",
    "#     if normalize:\n",
    "#         data_norm = (data.groupby(['experiment','function','freq','method'])[m.upper()].mean().reset_index()\n",
    "#                          .groupby(['experiment','function'])[m.upper()].min().reset_index()\n",
    "#                          .rename({m.upper():m.upper()+'_norm'}, axis=1))\n",
    "#         data = data.merge(data_norm, 'left')\n",
    "#         data[m.upper()+'_norm'] = data[m.upper()] / data[m.upper()+'_norm']\n",
    "    return data.reset_index(drop=True)\n",
    "\n",
    "def plot_one(exp, func, freq, ax, lbl_dict=None):\n",
    "    data = df.query(f'experiment == {exp!r} and function == {func!r} and freq == {freq}')\n",
    "#     for n,d in data.groupby('method'):\n",
    "    for n,row in data.iterrows():\n",
    "        lbl = row.method if lbl_dict is None else lbl_dict[row.method]\n",
    "        ax.plot(range(9,100), row[:91].values, label=lbl, linewidth=2, alpha=0.65) #/norm_check\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_pca(func, axs=None):#i added this new pca plot for ppsn paper, to present pcaplot with another format\n",
    "    exps = sorted([o.stem for o in Path().glob(f'*{func}*.npy')]) # retrieving file names\n",
    "    source_data = []\n",
    "    for exp in exps: source_data.append(pd.DataFrame(np.load(exp+'.npy')).assign(name=exp)) # reading files\n",
    "    df_source = pd.concat(source_data) # putting all files together in a pandas dataframe\n",
    "    d = df_source.iloc[:,:30] # grabs the values (30 dim)\n",
    "    pca = PCA(1) # initialize PCA\n",
    "    d_pca = pca.fit_transform(d) # reduces dimentions to 1\n",
    "    dd = df_source.name.to_frame() # grabs from df_source only the names of experiments\n",
    "    dd['value'] = d_pca[:,0] # adds the reduced dimentions to dd\n",
    "    plot_data = dd.copy() # putting the data in format to plot\n",
    "    plot_data['time'] = np.repeat(np.arange(100)[None], len(exps), 0).reshape(-1) # add time values \n",
    "\n",
    "    if axs is None: fig,axs = plt.subplots(1, 4, figsize=(16,0.8*len(exps))) # plot figures\n",
    "    \n",
    "    for exp,ax in zip(exps,axs):\n",
    "        texp,tfunc = exp.split('_')\n",
    "        t = plot_data.query(f\"name=={exp!r}\")\n",
    "        ax.plot(t['time'], t['value'] ,'-*', label=exp, c='crimson')\n",
    "        ax.set_title(f'{texp}-{tfunc.title()}')\n",
    "        ax.set_xlim(0,100)\n",
    "    plt.tight_layout()\n",
    "    return axs\n",
    "\n",
    "\n",
    "\n",
    "path = Path(f'../../data/cluster_results')\n",
    "\n",
    "df = get_data(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one plot only!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4, 1, figsize=(14,16))\n",
    "\n",
    "lbl_dict = None\n",
    "func='rosenbrock'\n",
    "plot_pca(func,axs)\n",
    "\n",
    "for ax_row,exp in zip(axs,exps):\n",
    "    ax_row.set_ylabel('pca')\n",
    "    ax_row.set_xlabel('time')\n",
    "    ax_row=ax_row.twinx()\n",
    "    plot_one(exp, func, freq, ax_row, lbl_dict)\n",
    "    ax_row.set_title(f'{exp}-{func.title()}')\n",
    "    ax_row.ticklabel_format(style='sci', scilimits=(0,5), useOffset=False)\n",
    "    ax_row.set_ylabel('nn_errors')\n",
    "    \n",
    "ax_row.legend(loc='upper right', bbox_to_anchor=(0, 0, 0.5, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "freq_lbl = f'{freq*10:02.0f}' if freq<1 else freq\n",
    "\n",
    "# fig.savefig(f'../../data/cluster_results/errorpca1{freq_lbl}.eps', dpi=400, format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "# errors and pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4, 3, figsize=(20,12))\n",
    "lbl_dict = None\n",
    "\n",
    "for ax_row,exp in zip(axs,exps):\n",
    "    for ax,func in zip(ax_row,funcs):\n",
    "        plot_one(exp, func, freq, ax, lbl_dict)\n",
    "        ax.set_title(f'{exp}-{func.title()}')\n",
    "        ax.ticklabel_format(style='sci', scilimits=(0,5), useOffset=False)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(0,0.15, 1.3, 0.8))#, bbox_to_anchor=(0,0, 0.5, 0.5))#best(0, -0.90, 0.5, 0.5)\n",
    "\n",
    "for i,func in enumerate(['sphere', 'rastrigin', 'rosenbrock']): plot_pca(func, axs[:,i])\n",
    "\n",
    "plt.tight_layout()\n",
    "freq_lbl = f'{freq*10:02.0f}' if freq<1 else freq\n",
    "\n",
    "fig.savefig(f'../../data/cluster_results/errorpca{freq_lbl}.eps', dpi=400, format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "# Plot errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only errors\n",
    "fig,axs = plt.subplots(4, 3, figsize=(18,10))\n",
    "lbl_dict = None\n",
    "\n",
    "for ax_row,exp in zip(axs,exps):\n",
    "    for ax,func in zip(ax_row,funcs):\n",
    "        plot_one(exp, func, freq, ax, lbl_dict)\n",
    "        ax.set_title(f'{exp}-{func.title()}')\n",
    "        ax.ticklabel_format(style='sci', scilimits=(0,5), useOffset=False)\n",
    "#         if ax.get_ylim()[1] < 1e5:\n",
    "# #             ax.get_yaxis().set_major_formatter(mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "#             ax.get_yaxis().set_major_formatter(mpl.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(0,0.15, 1.3, 0.8))#, bbox_to_anchor=(0,0, 0.5, 0.5))#best(0, -0.90, 0.5, 0.5)\n",
    "plt.tight_layout()\n",
    "freq_lbl = f'{freq*10:02.0f}' if freq<1 else freq\n",
    "\n",
    "fig.savefig(f'../../data/cluster_results/error{freq_lbl}.eps', dpi=400, format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = plot_pca('sphere')\n",
    "# fig.savefig(f'../../data/cluster_results/pcaPlot.eps', dpi=400, format='eps')\n",
    "# plot_function('rosenbrock')\n",
    "# plot_function('rastrigin')\n",
    "#save(str(path/'pcaPlot.png'), scale_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
